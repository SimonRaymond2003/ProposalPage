<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Simon Raymond" />

<meta name="date" content="2024-12-04" />

<title>A Predictive and Casual Analysis of Contributing Factors for 4th Down Attempt Conversions in the NFL</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Honours Proposal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">A Predictive and Casual Analysis of
Contributing Factors for 4th Down Attempt Conversions in the NFL</h1>
<h4 class="author">Simon Raymond</h4>
<h4 class="date">2024-12-04</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<div id="background" class="section level2">
<h2>Background</h2>
<p>The NFL is a multi-billion dollar industry that has seen rapid growth
within the USA and internationally. Davis and End (2010) argue that
successful NFL franchises have measurable economic impacts on their
local areas. This growth has placed more and more importance on the
performance of NFL teams as they fight to win games to increase the
popularity of their team. Teams are willing to invest time and money
into finding different strategies that assist their organization. One
such area that has received much attention is the idea of maximizing the
expected win percentages of teams. This leads teams to look to
strategies that may be outside of the cultural norm.</p>
<p>For many years in the NFL there seemed to be a consistent standard
that on 4th down your team will kick a field goal or punt the ball for
better field position. The only exception being the dying moments in a
game when teams are desperate. However data display tools have let us
see an increase in the overall attempt percentage of teams on 4th down
(Raymond, 2024). This is signalling a change in culture.</p>
<p>In the NFL there has been a increasing feeling that teams need to be
more aggressive on 4th downs. We have seen teams adopt this strategy.
Most famously is the Detroit lion’s mentality since the arrival of their
current head coach Dan Campbell. The lions adopted a aggressive strategy
to match their aggressive “biting off knee caps” mentality (Birkett,
2023). While the lions have seen success for the first time in years
they have also been criticized for their aggressive play calling. This
was seen in the 2023-24 playoff divisional round game in which the lions
failed a 4th down attempt that was painted as unnecessary (Sporting
News, 2024). After this failed 4th down attempt there seemed to be a
shift in momentum and the lions lost the game.</p>
</div>
<div id="research-problem" class="section level2">
<h2>Research Problem</h2>
<p>A result like this makes us ask the question “Did the lions make the
right call?”. This question seems to be getting answered as “yes” by the
current literature on this topic. However, we need to know if different
teams should go for it or not go for it depending on their situation and
team build. For example, it could be argued that the lions should have
attempted the crucial 4th down in the 2023-24 playoff divisional round
game. However, if the panthers (which were a significantly worse team)
were is that situation it could be argued that they should not have been
as aggressive. This is because the panthers could have had a worse
chance of being able to convert on 4th down.</p>
<p>On top of this we must be weary of any recommendation that is given
to a head coach. The truth is that we are not on the field, in the
locker rooms, or in team meeting. This means coaches may know more then
us in certain game time decision. We must approach this topic with the
idea of being more practical and clear to coaches.</p>
</div>
<div id="research-questions" class="section level2">
<h2>Research Questions</h2>
<p>This leads us to have a need to answer some key questions about 4th
downs in the NFL. First, is are there certain key predictable signals
that can be used to decide if a given team should attempt a 4th down?
Second, is what key factors or variables about players have predictive
power in 4th down attempts? In other words are there players that are
more important in 4th down situations when compared to other situations.
Finally, do these key factors about players have a casual effect on the
outcome of 4th down attempts? Answering these questions will allow
coaches to look for key signals in 4th down situations and to know which
players to start on that 4th down if it is decided to attempt. This also
can be applied in discovering specialty players that are overlooked due
to poor performances in situations that are not similar to 4th down.</p>
</div>
</div>
<div id="literature-review" class="section level1">
<h1>Literature Review</h1>
<div id="risk-aversion" class="section level2">
<h2>Risk aversion</h2>
<p>Much of this problem revolves around the idea that NFL coaches are
acting overly averse to risk which is lowering their expected wins.
Romer (2006) found that teams had begun to move towards a more
conservative or safe strategy in the NFL. He argues that teams value
successful gambles more then the expected win percentage in a game. He
theorizes that the poor decision making is either due to risk aversion
or it is due to poor information.</p>
<p>To further this point using matching analysis, Yam and Lopez (2018)
quantified this conservative decision-making, finding that teams could
gain approximately 0.4 wins per year by being more aggressive on fourth
downs.</p>
<p>Goff and Locke (2019) found when revisiting Romer’s framework that
Romer’s core findings are still held to be true. However they argue that
overly conservative calls are not due to poor decision making. Instead
they point to risk aversion as they estimate that coaches are willing to
give up two-thirds of a expected point to avoid the uncertainty of
fourth down attempts.</p>
<p>On top of this, there seems to be evidence that coaches are more
cautious when their job is on the line. Owens and Roach (2018) found
that in the NCAA coaches are relatively more conservative when they are
more likely to be fired. At the same time they found when a coach was
likely to be promoted that the coach is more aggressive then normal.</p>
</div>
<div id="momentum" class="section level2">
<h2>Momentum</h2>
<p>If a team feels to be “on fire” should they be more aggressive since
they feel to have momentum? The most famous literature in this is on the
fallacy of the “hot hand”. The hot hand is a cognitive bias that leads
people to believe that a person who has a successful outcome is more
likely to have a successful outcome in future attempts. Gilovich et
al. (1985) investigated the “hot hand” and “shooting streaks” in basket
ball. They found that both players and fans believed in the fallacy
despite shots being independent of each other. Losak et al. (2023)
similarly discovered that fantasy baseball users gravitated towards
“hot” players. At the same time they were unable to identify a viable
hot hand strategy in DraftKings DFS baseball.</p>
<p>Despite these common findings there does seem to be some evidence of
momentum existing in the NFL. Roebber et al.(2022, p. 2) defined
momentum in the NFL as “the sustained increase in win probability by a
single team over the course of at least 2 successive changes in
possession”. With this definition they found that streaks of win
probability in football are non-random and are in fact predictable with
Artificial Neural Network Models.</p>
<p>Lehman &amp; Hahn (2013) looked to identify momentum across and
within games in the NFL. Within-period momentum was found to encourage
teams to take more risks. Negative within-period momentum was in-turn
found to encourage teams to take less risks. It was also discovered that
across-period momentum has a effect only until a within period momentum
was established in a game.</p>
</div>
<div id="heckman-correction" class="section level2">
<h2>Heckman correction</h2>
<p>The Heckman correction is a two-step estimation process that is used
to correct for sample selection bias (Heckman, 1979). The first step is
to estimate the probability of selection into the sample. The second
step is to estimate the outcome of interest. Heckmans original paper was
focused on applying probit and linear models for this method. However,
due to the non-linearities in NFL data we will be looking to apply a
non-parametric model to our situation. I am currently in the process of
looking at recent literature and applications of self sample selection
bias corrections with non-parametric models.</p>
<p>Here are some papers that I will be looking at:</p>
<ul>
<li>Klein and Spady (1993)</li>
<li>Das, Newey, and Vella (2003)</li>
<li>Cook (2022)</li>
</ul>
<p>I currently am looking most specifically at semi-parametric
models.</p>
</div>
<div id="research-gap" class="section level2">
<h2>Research Gap</h2>
<p>The gap in the current research revolves around the gap in quality
data. Currently we see many studies include team grades or summary
statistics about teams that are playing against each other. This type of
generalization is needed for econometric models that cannot handle large
amounts of variables. However, our non-parametric models will be able to
handle data with thousands of different variables. To take advantage of
this we will have information about every single player that is on the
field when the ball is snapped. This will allow us to have better
prediction power then previous researchers. This lack of work
accomplished with highly specific data then in turn creates a lack in
researchers identifying key variables about different players in the
field. This is why our combined approach of predictive and casual tools
will be so effective. We will be able to see what variable are or are
not having a effect on 4th down conversions.</p>
</div>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<div id="play-by-play-pbp" class="section level2">
<h2>Play by Play (PBP)</h2>
<p>Our data consists of play by play data from the NFL. This data is
pulled from the nflverse package in R (Carl et al., 2024). The data
ranges from 2016 to 2023. The reason for this is that after 2016 the NFL
started to put tracking chips in NFL player’s jerseys. This gives us
information after 2016 of what players are on the field for each snap.
As a note a weeks 16-18 in 2023 are missing gsis_ids of who was on the
field and the data in 2016 is described as not as reliable. A gsis_id is
a unique identifier for a player and it crucial in our work.</p>
<p>To create my data I have merged play by play data, participation
data, roster data, and injury data. However, we may create different
versions of our data depending on our models that we choose to use.</p>
<p>First, we have a third down data set. This data has the purpose of
allowing us to test our Heckman Variable’s validity in showing that a
variable has no predictive power on a third down conversion. We then use
this to bolster our argument that the variable in question has no
predictive power on a 4th down conversions. We also will have a fourth
down “attempts” data set. This data set will be used to show that our
Heckman Correction variable does have strong prediction power on the
decision to attempt a 4th down or not. (this situation is more
unbalanced). Finally, the end goal is to be using data of purely 4th
down attempts to predict the conversion of a play.</p>
<p>While it is subject to change the 3rd down data set has 56,000+ rows
and 1300+ columns. The 4th down attempts data set has 33,000+ rows and
1300+ columns.</p>
</div>
<div id="pro-football-focus-pff" class="section level2">
<h2>Pro Football Focus (PFF)</h2>
<p>Our weekly player data is a combination of reports from Pro Football
Focus, (2024) from 2016 to 2023. This data is downloaded in the form of
different positional reports. For example, we downloaded the receiving
reports labeled as “Receiving Grades, Receiving Depth, Receiving
Concept, and Receiving vs Scheme”. Each row in these reports contains
information how a player did in certain areas covered by that report
that week. This by itself is useless to us, as we need to merge every
report into each other.</p>
<p>We ended up with a data set that is 158,000+ rows and 1,500+ columns.
Each column is a different stat that may or may not apply to a player
(e.g. a receiving grade does not apply to a DE).</p>
<p>So for each row in this engineered data set there is a player, their
basic information, the year and week, and 1,500+ variables of how that
player preformed in a specific week.</p>
</div>
<div id="merging" class="section level2">
<h2>Merging</h2>
<p>A problem we encountered is that the PFF players do not have a
gsis_id. They instead have a pff_id. Unfortunately not all players with
a gsis_id have a available pff_id. On top of that the names between the
data sets do not always match up. Currently I am working on different
methods of matching these players between datasets. This match I
currently am doing in a multi-step process off of standardized names,
parts of names, positions, years played, and teams. For the players that
have a pff_id assigned to their gsis_id this matching process is not
needed. As a part of our contribution to this field of study I will be
providing the dataset of 4900+ players with matched PFF and GSIS IDs. If
you desire the code for this process to extend it to other years or play
types please reach out to me via email.</p>
<p>The most key aspect of this entire thesis is the merging of the PFF
and PBP datasets. We can start with how in our PBP data we have the
gsis_ids of every player that was on the field at the time of the play.
A gisi_id is the main unique identifier for the player. So we need to
take our PFF data and for each player merge it into the PBP data.</p>
<p>We have multiple types of PBP datasets that we are merging PFF data
into. First we have a 3rd down data set that is used to bolster our
argument that are exogenous variable that is used for correction of self
selection sample bias has no effect on 4th down completions.</p>
<p>Our 4th down data set on the other hand has multiple uses. First, it
will be used to show that our exogenous variable has a effect on the
decision to attempt a 4th down. In this case the dependent variable is
the decision to attempt a 4th down. Second, the 4th down data will be
filtered down to situations where a team “went for it” with a run or a
pass play. In this case the dependent variable is the completion of a
4th down.</p>
<p>I currently am hesitant to be stating the exact numbers of columns
and rows within this data as these numbers will change as we engineer
new features, generalize our existing features or filter our data more.
However both the 3rd down and 4th down data currently have over 45,000
columns without any forms of generalization. Our 3rd down data set
currently consists of 56,000+ rows and our 4th down data set consists of
33,000+ rows. However when our 4th down set is filtered to only include
“went for it” plays we get 400-900 observations a year.</p>
<p>Here are some general areas that the data captures:</p>
<ul>
<li>Game situation (down, distance, score, time remaining,
location)</li>
<li>Player specifics (“rushing years/passing yards/blocking grades” in
the past seasons)</li>
<li>Physical player traits (height, weight, age, etc.)</li>
<li>Player injury history (e.g. days since last injruy)</li>
<li>Team injury history (e.g. specific type of injuries in last
week/year)</li>
</ul>
</div>
</div>
<div id="methodology" class="section level1">
<h1>Methodology</h1>
<div id="measuring-accuracy" class="section level2">
<h2>Measuring Accuracy</h2>
<p>In order to measure the accuracy of our models we will be using the
area under the curve (AUC) of the ROC curve. This is a common metric
used in binary classification problems. The ROC curve is a plot of the
true positive rate against the false positive rate for the different
possible thresholds of a confusion table. These values will be tested
and reported over 10,000 tests of bootstrapped test data.</p>
<p>Our methodology involves two main types of tools. These are
predictive tools and casual econometrics tools.</p>
</div>
<div id="predictive-tools" class="section level2">
<h2>Predictive Tools</h2>
<p>These tools are going to be used to predict the outcome of a 4th down
attempt. If these outcomes of these predictions are acceptable we will
identify what variables had predictive power in our non-parametric
models. The models that will be used are Random Forest, GBM boosting,
XGBoosting, and possibly Neural Networks. All boosting models will be
tuned with some form of grid search.</p>
</div>
<div id="casual-econometrics-tools" class="section level2">
<h2>Casual econometrics tools</h2>
<p>After our predictive modeling we will be left with variables that
have prediction power on the outcome of a 4th down attempt. Then we turn
to our casual econometrics tools. Our situation faces one key problem.
There is selection bias around the 4th down attempts. This means that we
never see the outcomes of 4th down attempts that never happened. In
those situations the ball was punted or a field goal was attempted. To
try to control this selection bias we will be using a Heckman
correction. A form of OLS can be pursued with the Heckman correction.
However, we will also be looking to apply some form of non-linear model
to our situation. This is due to the intense non-linearities that are
found in NFL data.</p>
<p>This self selectiong bias is created in our current world by the fact
that the coach is making a decision about “going for it” or not “going
for it” on 4th down. When we control for this we are attempting to
create a world where the 4th down attempts that we see are free from
bias. This is to say it creates a world where we do actaully see all the
4th down attempts that could have happened.</p>
<p>The Heckman correction requires a key exogenous variable that
predicts 4th attempts but not the results of those attempts. The
variable I propose is score differential. The score differential without
a doubt has predicting power on whether or not a team attempts a 4th
down. The question is does it have prediction power on the actual
conversion of the 4th down. I would argue not.</p>
<p>My one fear was originally that score differential signals a “better”
team. Then since that team is “better” the 4th down result will receive
prediction power from the score differential. However, if we account for
how good the team are I believe that argument would not hold up. Even
without accounting for how good teams are I found that the score
differential was almost useless for predicting the 3rd down conversion
result (in this case we used 3rd down plays to stand in for 4th down
conversions). We can examine the following example. Imagine a world
where the panthers (weaker team) are playing the saints (average team).
The panthers are losing by 30 points so the score differential is -30.
Obviously here the panthers probably have a below average chance of
conversion on a 4th down. However on 4th down the teams swap and the
chiefs (better team) take over for the panthers. I don’t think that it
is fair to say that the 30 point deficit will make it harder for the
chiefs to convert on 4th down. Similarly one may say that the Chiefs may
have a tougher time converting on this 4th down because they are playing
in a more desperate situation. The factors though of this desperate
situation can also be accounted for.</p>
<p>This seems to be backed up by the <a
href="#begining-analysis">beginnings of my analysis</a>.</p>
</div>
</div>
<div id="expected-outcomes" class="section level1">
<h1>Expected Outcomes</h1>
<p>Currently we are predicting 3rd down conversions with a AUC that is
in the mid 60s range. This is not incredible but it makes sense as the
baseline predictions only account for some basic situation variables. I
expect to have presentable AUC in the 80s range when we work on our
properly merged 4th down data set. Then i believe that variables will be
identified that will be proven to have a casual effect on 4th down
conversions. In this process however it is important to recognize the
significance of finding a variable to not have prediction power or a
casual effect.</p>
</div>
<div id="timeline" class="section level1">
<h1>Timeline</h1>
<ul>
<li>I will have the data merged by the beginning of the winter 2025
semester (names matching).</li>
<li>We then will be able to move to modeling and analysis.</li>
</ul>
</div>
<div id="begining-analysis" class="section level1">
<h1>Begining Analysis</h1>
<pre class="r"><code>model_3rd3 &lt;- read_csv(&quot;model_3rd3.csv&quot;)</code></pre>
<pre><code>## Rows: 7022 Columns: 20
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## dbl (20): week, ydstogo, yardline_100, posteam_timeouts_remaining, defteam_t...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>model_4th3 &lt;- read_csv(&quot;model_4th3.csv&quot;)</code></pre>
<pre><code>## Rows: 4226 Columns: 19
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## dbl (19): week, attempt, ydstogo, yardline_100, minutes_remaining, posteam_t...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div id="notes-before-proceeding" class="section level2">
<h2>Notes before proceeding</h2>
<ul>
<li>For display purposes most of the code that produces the data and
plots are not shown. However, the code will be made available via my
personal github page (<a href="https://github.com/SimonRaymond2003"
class="uri">https://github.com/SimonRaymond2003</a>).</li>
<li>The OLS model takes no account for Heteroskedasticity or
Autocorrelation.</li>
<li>The current data ignores how good the teams are (offensive and
defensive). For that reason our prediction power doesn’t seem
incredible. Howeve, with the proper data that we are creating we can
improve our results.</li>
<li>The relationships are definitely non-linear. In some cases though, I
could engineer the data to help OLS. For example the minutes left in the
game could be two columns one that is the half and one that is the time
from 0-30. However, our end goal is to be using a non-linear model.</li>
<li>I added a random (simulated/useless) variable to the data to give us
a reference point of what variables are useless in our random forest
model.</li>
<li>Week 1 was removed from the data due to how we created some of our
variables.</li>
<li>The data is scaled.</li>
<li>the ROCR curves are from one run of random forest (double check if I
don’t need to loop it because it is random forest)</li>
</ul>
</div>
<div id="measures-of-prediction-power-random-forest"
class="section level2">
<h2>Measures of prediction power Random Forest</h2>
<div id="mdi-gininode-purity" class="section level3">
<h3>MDI (gini/node purity)</h3>
<p>As Gini impurity decreases (meaning nodes become more pure), the MDI
value increases.</p>
<p>This measures how good a variable is at promoting node purity during
the splits. This is for the training of the model. This leads MDI to not
always be the best measure. MDI thrives when variables have a lot of
categories, variability or are continuous. For example, a categorical
variable with 10 levels will have a higher MDI than a binary
variable.</p>
<p>That is why the random variable did good in this measure. The splits
in the trees will sometimes use useless variables. This is because it
fits the training data and it is very normal for RF to use bad
predictors (that is the entire point of randomforest). However MDI can
make it appear that unimportant variables are in fact important.</p>
</div>
<div id="mda-mean-descrease-in-accuracy" class="section level3">
<h3>MDA (Mean Descrease in Accuracy)</h3>
<p>This looks are more how the model would do if we removed the variable
in question from the model. A negative MDA means that the model would do
better without the variable. It is more robust and we need to pay more
attention to this rather than MDI.</p>
</div>
<div id="partial-dependency-plots-pdp" class="section level3">
<h3>Partial Dependency Plots (PDP)</h3>
<p>Partial dependency plots in Random Forests show how one variable
affects predictions while accounting for all other variables in a
realistic way. Rather than arbitrarily fixing other variables to
constants, the method uses all actual combinations of other variables
from the training data.</p>
<p>For example, if we want to understand how score differential affects
fourth down decisions, the process works like this: For each potential
score differential value (say -14 points), the model temporarily sets
every play in the dataset to have that score differential while keeping
all other features (like field position, time remaining, etc.) exactly
as they occurred in real games. It then averages all these predictions
to show the isolated effect of being down 14 points.</p>
</div>
<div id="a-caution-with-pdps" class="section level3">
<h3>A Caution with PDPs</h3>
<p>To issue a strong warning however, here is a PDP of a variable that
has absolutely no connection with 3rd down conversions:</p>
<p>Here is the distribution plot of the random variable we are
using:</p>
<pre class="r"><code>rv_plot</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Here is the PDP of the random variable:</p>
<pre class="r"><code># Display the plot
pdp_random</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>This plot will seem confusing. Why does a useless simulated variable
seem to have predictive power. This random variable does not have
predictive power or a casual effect just because of the PDP plot! As we
will see, this random variable has negative MDA. While it has a very
high MDI that is simply due to the specificness of the variable. This
plot displays how the random forest model is using it. Models like
random forest and XGBoosting are designed to give a voice to weak
predictors. The PDP simply shows how the model is using that variable.
The model may be incorrectly picking up on a pattern that is not truly
within our data. This is proven by the variable’s lack of use near to
the center of its probability distribution. However, as we move away
from the from the center of the random variable’s distribion we get more
specificness that the random forest model thinks is useful for
prediction. There are less observations near the tails of our
distribution and therefore more opportunities to make a obscure split to
help our leaf node purity(gini score) in the training process. This
example needs to serve as a strong caution when observing our PDP plots
in the following analysis.</p>
</div>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<div id="points-about-the-data" class="section level3">
<h3>Points about the data</h3>
<p>The data we are using is from the 2023 NFL season. We ended up
removing the first week of the season due to how we created some of our
variables. In preparing our data for OLS analysis we decided to remove
the temperature and wind variables since they contained NA values. If
the score differential was above 30 or below -30 then we removed that
observation. The non-binary variables were scaled while preserving the
column names.</p>
</div>
</div>
<div id="variable-descriptions" class="section level2">
<h2>Variable Descriptions</h2>
<ul>
<li><code>attempt</code> (4th down data): Binary indicator (1/0)
representing whether a coach elected to attempt a 4th down conversion
rather than punt or attempt a field goal</li>
<li><code>converted</code> (3rd down data): Binary indicator (1/0)
showing if the play resulted in a successful conversion for a first
down</li>
<li><code>down1_pct</code>: Running play percentage on 1st downs so far
in the game</li>
<li><code>down2_pct</code>: Running play percentage on 2nd downs so far
in the game</li>
<li><code>down3_pct</code>: Running play percentage on 3rd downs so far
in the game</li>
<li><code>opp_scss</code> (previously <code>successes</code>): Number of
successful 4th down conversions by the opposing team in their previous
game</li>
<li><code>opp_fails</code> (previously <code>failures</code>): Number of
failed 4th down attempts by the opposing team in their previous
game</li>
<li><code>score_diff</code>: Point differential at the time of the play
(positive values indicate the offensive team is winning)</li>
<li><code>min_rem</code> (previously <code>minutes_remaining</code>):
Minutes remaining in the game</li>
<li><code>ydstogo</code>: Yards needed to achieve a first down</li>
<li><code>yardline_100</code>: Distance in yards from the opponent’s
endzone (e.g., 75 means the ball is on the offensive team’s 25-yard
line)</li>
<li><code>rush</code> (3rd down data only): Binary indicator (1/0) for
whether the play was a rushing attempt or a pass</li>
<li><code>offtimes</code> (previously
<code>posteam_timeouts_remaining</code>): Number of timeouts remaining
for the offensive team</li>
<li><code>deftimes</code> (previously
<code>defteam_timeouts_remaining</code>): Number of timeouts remaining
for the defensive team</li>
<li><code>week</code>: Week number of the NFL season (Week 1
excluded)</li>
<li><code>prep_days</code>: Number of days the team had to prepare for
this game</li>
<li><code>home</code>: Binary indicator (1/0) for whether the offensive
team is playing at home</li>
<li><code>dome</code>: Binary indicator (1/0) for whether the game is
being played in a dome</li>
<li><code>KICKOFF</code>: Binary indicator (1/0) for whether the
offensive team received the ball via kickoff</li>
<li><code>PUNT</code>: Binary indicator (1/0) for whether the offensive
team received the ball via punt Note: If both KICKOFF and PUNT are 0,
the team received possession through another method (e.g.,
turnover)</li>
<li><code>random_var</code>: Simulated random variable included as a
reference point for evaluating variable importance in our models</li>
</ul>
<pre class="r"><code>glimpse(model_3rd3)</code></pre>
<pre><code>## Rows: 6,915
## Columns: 20
## $ converted    &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, …
## $ down1_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ down2_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ down3_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ opp_scss     &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ opp_fails    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ score_diff   &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ min_rem      &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ ydstogo      &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ yardline_100 &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ rush         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,…
## $ offtimes     &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 2, 2, 2, 2,…
## $ deftimes     &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3,…
## $ week         &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…
## $ prep_days    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ home         &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,…
## $ dome         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ KICKOFF      &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,…
## $ PUNT         &lt;dbl&gt; 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ random_var   &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;</code></pre>
<pre class="r"><code>glimpse(model_4th3)</code></pre>
<pre><code>## Rows: 4,163
## Columns: 19
## $ attempt      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, …
## $ down1_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ down2_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ down3_pct    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ opp_scss     &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ opp_fails    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ score_diff   &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ min_rem      &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ ydstogo      &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ yardline_100 &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ offtimes     &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,…
## $ deftimes     &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,…
## $ week         &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…
## $ prep_days    &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;
## $ home         &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,…
## $ dome         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ KICKOFF      &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,…
## $ PUNT         &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,…
## $ random_var   &lt;dbl[,1]&gt; &lt;matrix[26 x 1]&gt;</code></pre>
</div>
<div id="ols" class="section level2">
<h2>OLS</h2>
<div id="th-down-will-the-coach-attempt-to-go-for-it"
class="section level3">
<h3>4th down “will the coach attempt to go for it?”</h3>
<pre class="r"><code># Fit OLS model
OLS_4th &lt;- lm(attempt ~ ., data = model_4th3)
summary(OLS_4th)</code></pre>
<pre><code>## 
## Call:
## lm(formula = attempt ~ ., data = model_4th3)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7151 -0.2742 -0.1290  0.2232  1.2636 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.321665   0.032383   9.933  &lt; 2e-16 ***
## down1_pct     0.007858   0.006530   1.203   0.2289    
## down2_pct    -0.004963   0.006890  -0.720   0.4714    
## down3_pct     0.011405   0.006487   1.758   0.0788 .  
## opp_scss      0.009169   0.006116   1.499   0.1339    
## opp_fails    -0.001308   0.006023  -0.217   0.8281    
## score_diff   -0.093445   0.006343 -14.733  &lt; 2e-16 ***
## min_rem      -0.073849   0.006472 -11.410  &lt; 2e-16 ***
## ydstogo      -0.121609   0.006180 -19.679  &lt; 2e-16 ***
## yardline_100 -0.053069   0.006266  -8.469  &lt; 2e-16 ***
## offtimes     -0.054160   0.008803  -6.152 8.36e-10 ***
## deftimes      0.020711   0.008597   2.409   0.0160 *  
## week          0.002297   0.001162   1.977   0.0481 *  
## prep_days    -0.002884   0.006045  -0.477   0.6334    
## home          0.001589   0.012054   0.132   0.8952    
## dome          0.020580   0.015522   1.326   0.1849    
## KICKOFF      -0.027270   0.018515  -1.473   0.1409    
## PUNT         -0.024252   0.018353  -1.321   0.1864    
## random_var   -0.006351   0.005965  -1.065   0.2871    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3842 on 4144 degrees of freedom
## Multiple R-squared:  0.201,  Adjusted R-squared:  0.1975 
## F-statistic: 57.92 on 18 and 4144 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>vif(OLS_4th)</code></pre>
<pre><code>##    down1_pct    down2_pct    down3_pct     opp_scss    opp_fails   score_diff 
##     1.202624     1.338873     1.186753     1.054833     1.023034     1.134456 
##      min_rem      ydstogo yardline_100     offtimes     deftimes         week 
##     1.181236     1.076950     1.107316     1.237650     1.281292     1.037317 
##    prep_days         home         dome      KICKOFF         PUNT   random_var 
##     1.030535     1.024332     1.023471     2.398000     2.255370     1.003373</code></pre>
</div>
<div id="rd-down-will-the-play-convert-to-a-1st-down"
class="section level3">
<h3>3rd down “will the play convert to a 1st down?”</h3>
<pre class="r"><code># Fit OLS model
OLS_3rd &lt;- lm(converted ~ ., data = model_3rd3)
summary(OLS_3rd)</code></pre>
<pre><code>## 
## Call:
## lm(formula = converted ~ ., data = model_3rd3)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7277 -0.3986 -0.2124  0.4833  1.2555 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.3623399  0.0336891  10.755  &lt; 2e-16 ***
## down1_pct     0.0070500  0.0060850   1.159 0.246667    
## down2_pct    -0.0057824  0.0063937  -0.904 0.365822    
## down3_pct     0.0084054  0.0060313   1.394 0.163471    
## opp_scss      0.0002207  0.0057122   0.039 0.969176    
## opp_fails     0.0001537  0.0056266   0.027 0.978212    
## score_diff   -0.0021870  0.0059106  -0.370 0.711383    
## min_rem       0.0059934  0.0059996   0.999 0.317846    
## ydstogo      -0.1527965  0.0058681 -26.038  &lt; 2e-16 ***
## yardline_100  0.0199008  0.0057668   3.451 0.000562 ***
## rush          0.0820480  0.0137360   5.973 2.44e-09 ***
## offtimes      0.0061106  0.0086247   0.709 0.478657    
## deftimes      0.0024305  0.0089623   0.271 0.786251    
## week         -0.0011351  0.0010727  -1.058 0.290020    
## prep_days    -0.0062438  0.0056286  -1.109 0.267338    
## home          0.0062293  0.0112071   0.556 0.578338    
## dome          0.0047764  0.0144059   0.332 0.740235    
## KICKOFF       0.0143616  0.0172821   0.831 0.405995    
## PUNT         -0.0137044  0.0171643  -0.798 0.424651    
## random_var   -0.0001875  0.0055568  -0.034 0.973087    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4617 on 6895 degrees of freedom
## Multiple R-squared:  0.1127, Adjusted R-squared:  0.1103 
## F-statistic:  46.1 on 19 and 6895 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>vif(OLS_3rd)</code></pre>
<pre><code>##    down1_pct    down2_pct    down3_pct     opp_scss    opp_fails   score_diff 
##     1.201236     1.326194     1.180097     1.058535     1.027062     1.133359 
##      min_rem      ydstogo yardline_100         rush     offtimes     deftimes 
##     1.167745     1.117116     1.078863     1.097724     1.173236     1.210723 
##         week    prep_days         home         dome      KICKOFF         PUNT 
##     1.037015     1.027783     1.018693     1.021203     2.410760     2.251229 
##   random_var 
##     1.001742</code></pre>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<div id="th-down-will-the-coach-attempt-to-go-for-it-1"
class="section level3">
<h3>4th down “will the coach attempt to go for it?”</h3>
<p>Here we display the results on a 4th down random forest model. This
model predicts attempts and is run with a ntree = 1500. We are reporting
Out Of Bag results.</p>
<pre class="r"><code># Print results
print(importance_df)</code></pre>
<pre><code>##        Variable          0           1 MeanDecreaseAccuracy MeanDecreaseGini
## 1       ydstogo 126.002710 185.8722726          195.2746981        330.65192
## 2    score_diff  62.623935 108.6540273          113.2869194        176.57889
## 3       min_rem  59.775285 101.6495425          102.9746315        194.10616
## 4  yardline_100  47.413516 106.6503391           96.9275630        199.55927
## 5      offtimes  20.350509  25.9233860           31.6439314         35.75933
## 6      deftimes  21.810413   3.1921930           21.4321912         26.21388
## 7          week   0.184814   9.0178930            5.0208110         59.58649
## 8     down1_pct   1.040355   7.1406478            4.9573135         78.50463
## 9     down2_pct   2.341873   4.8599441            4.6730988         76.33280
## 10    down3_pct  -2.834120   8.4329170            2.3459534         78.25188
## 11      KICKOFF   3.322896  -2.1770402            1.6336814         13.59309
## 12         home  -3.190402   6.2082496            1.1166262         14.37036
## 13         dome  -2.998111   3.3339568           -0.4614668         10.29600
## 14   random_var  -1.503282  -0.1644719           -1.3080810        106.82509
## 15    prep_days  -4.433239   3.4822121           -1.6567989         33.23136
## 16         PUNT  -2.835734  -0.3526549           -2.6332261         12.66409
## 17     opp_scss  -5.791980   3.3702832           -2.9676177         36.36877
## 18    opp_fails  -5.976563   3.5040960           -2.9795022         38.79649</code></pre>
<pre class="r"><code>print(paste(&quot;OOB AUC:&quot;, round(oob_auc, 3)))</code></pre>
<pre><code>## [1] &quot;OOB AUC: 0.881&quot;</code></pre>
<pre class="r"><code># Plot variable importance
varImpPlot(rf4,
           sort = TRUE,
           main = &quot;Variable Importance Plot&quot;,
           n.var = min(20, ncol(model_4th3)-1))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>rocr_4th</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>This is a very good AUC despite missing how good the teams are. This
makes sense as NFL coaches are trying to make optimal decisions for
their team to win.</p>
<pre class="r"><code>pdp_4th</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Why do we see score differential influencing prediction of attempts
in our random forest model in this way? First we note that if a team is
losing they are more desperate. These more desperate teams are more
likely to go for it on 4th down. On the other hand if a team is winning
then they feel more aggressive. These teams that are winning are also
more likely to be a better team. This can be captured with other
variables as we proceed with our research.</p>
</div>
<div id="rd-down-will-the-play-convert-to-a-1st-down-1"
class="section level3">
<h3>3rd down “will the play convert to a 1st down?”</h3>
<p>Here we display the results of a 3rd down random forest model. This
model predicts conversion and is run with a ntree = 1500. We are
reporting Out Of Bag results.</p>
<pre class="r"><code># Print results
print(importance_df)</code></pre>
<pre><code>##        Variable           0           1 MeanDecreaseAccuracy MeanDecreaseGini
## 1       ydstogo 83.05588524 113.3980429          135.4501676        450.67840
## 2          rush  4.47797643  30.9748465           26.9545298         61.24723
## 3  yardline_100 13.63186583  -5.5596880            7.0536067        317.15580
## 4       min_rem  3.54461863   0.9815335            3.4842691        347.34838
## 5     down3_pct  4.31802415  -3.2429980            1.2890553        244.78464
## 6      opp_scss -1.48554389   3.5069321            1.0835659        114.50682
## 7      deftimes  2.39263831  -2.1641496            0.5150940         61.97243
## 8    score_diff -0.27079796   0.7225512            0.2600402        225.60373
## 9     down2_pct -1.79179734   2.4421374            0.2068352        240.72539
## 10      KICKOFF -3.61701302   4.1027136           -0.1029305         42.81354
## 11    prep_days -0.06818342  -0.3356903           -0.2627515        108.04845
## 12         week  0.22143290  -1.0075717           -0.4993756        183.80205
## 13         PUNT -1.84481468   1.1133976           -0.6286028         41.50121
## 14    opp_fails -2.82654634   0.2479793           -2.1148818        122.79910
## 15         dome -2.67653420  -0.4402697           -2.4471017         32.10255
## 16   random_var -0.15735623  -3.6936104           -2.4807033        347.91162
## 17         home -1.80997483  -2.0503768           -2.6621262         42.00402
## 18    down1_pct -4.88187596   0.8716234           -3.3666895        241.30277
## 19     offtimes -4.05956285  -2.0547905           -4.6976606         59.08749</code></pre>
<pre class="r"><code>print(paste(&quot;OOB AUC:&quot;, round(oob_auc, 3)))</code></pre>
<pre><code>## [1] &quot;OOB AUC: 0.668&quot;</code></pre>
<pre class="r"><code># Plot variable importance
varImpPlot(rf3,
           sort = TRUE,
           main = &quot;Variable Importance Plot&quot;,
           n.var = min(20, ncol(model_3rd3)-1))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>rocr_3rd</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>This is a bad AUC which currently makes sense as it is a baseline.
This example does not have how good the teams or players are.</p>
<pre class="r"><code># Create plot
pdp_3rd &lt;- ggplot(plot_data, aes(x = score_diff, y = probability)) +
 geom_line(color = &quot;#377EB8&quot;, size = 1.2) +
 labs(
   title = &quot;Effect of Score Differential on 3rd Down Conversion Probability&quot;,
   x = &quot;Score Differential (Points)&quot;,
   y = &quot;Probability of 3rd Down Conversion&quot;
 ) +
 theme_minimal() +
 theme(
   plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;),
   panel.grid.minor = element_blank()
 )</code></pre>
<pre class="r"><code>pdp_3rd</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Why does the RF model use score differential in the way that it does?
If the score differential is 0 then the team is acting as it should. If
a team is winning that team is often overly cautious which is bad in
terms of your performance. If a team is losing then that team may have
to be overly aggressive which is also bad in terms of your performance.
Especially because this type of aggresion is not the calculated form but
it is often the forced kind. These points are once again variables that
we can control for when using score differential as our exogenous
variable in our selection bias correction. For example we have the yards
to go for 4th downs which is a huge indicator of desperation along with
the time left in the game. We can also look to use how far the QB is
throwing the ball or even the play call and formation to control for
desperation.</p>
</div>
</div>
<div id="proof-of-non-linearities" class="section level2">
<h2>Proof of non-linearities</h2>
<p>As we can imagine NFL data is riddled with different types of
non-linearities. For example the relationship between the score
differential and the probability of a 4th down attempt is not linear.
There are jumps in effect around scoring intervals of 3, 7 and 8 due to
the scoring system in the NFL. This leads us to look more at using
non-parametric models in our analysis. While the self sample selection
bias correction was founded as a parametric model there is literature
that supports us using a non-parametric model.</p>
<p>In this following section keep in mind that our OOB AUC for our
random forest model with 4th down data was 0.88. In this case we are
predicting if a team will attempt a 4th down pass or rushing play. If we
see that a linear regression model is unable to compete with our random
forest model that is a sign of non-linearities in the data. In that case
we will go a step further and apply boosting methods.</p>
<p>Here we will display the results of a algorithm that runs the lm()
function which preforms OLS on 1000 bootstrapped samples of the 4th down
data. The reported values are from the test samples that are
bootstrapped.</p>
<pre class="r"><code># Plot results
plot(auc, col = &quot;red&quot;, main = &quot;AUC Distribution for Linear Model&quot;, 
    xlab = &quot;Iteration&quot;, ylab = &quot;AUC&quot;)
abline(h = mean(auc), col = &quot;blue&quot;, lwd = 2, lty = 2)
abline(h = mean(auc) - 1.96 * sd(auc), col = &quot;green&quot;, lwd = 2, lty = 3)
abline(h = mean(auc) + 1.96 * sd(auc), col = &quot;green&quot;, lwd = 2, lty = 3)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code># Print summary statistics
cat(&quot;Mean AUC:&quot;, mean(auc), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.7951987</code></pre>
<pre class="r"><code>cat(&quot;95% CI: [&quot;, mean(auc) - 1.96 * sd(auc), &quot;,&quot;, mean(auc) + 1.96 * sd(auc), &quot;]\n&quot;)</code></pre>
<pre><code>## 95% CI: [ 0.774153 , 0.8162443 ]</code></pre>
<p>We see a significantly worse performance then with a random forest
model.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<p>Cook, J. A. (2022). Sample-Selection-Adjusted Random Forests.
International Journal of Data Science and Analytics, 14, 375-388. <a
href="http://dx.doi.org/10.2139/ssrn.4225014"
class="uri">http://dx.doi.org/10.2139/ssrn.4225014</a></p>
<p>Das, M., Newey, W. K., &amp; Vella, F. (2003). Nonparametric
estimation of sample selection models. The Review of Economic Studies,
70(1), 33-58. <a href="https://doi.org/10.1111/1467-937X.00236"
class="uri">https://doi.org/10.1111/1467-937X.00236</a></p>
<p>Gilovich, T., Vallone, R., &amp; Tversky, A. (1985). The hot hand in
basketball: On the misperception of random sequences. Cognitive
Psychology, 17(3), 295-314. <a
href="https://doi.org/10.1016/0010-0285(85)90010-6"
class="uri">https://doi.org/10.1016/0010-0285(85)90010-6</a></p>
<p>Goff, B. L., &amp; Locke, C. (2019). Revisiting Romer: Digging Deeper
Into Influences on NFL Managerial Decisions. Journal of Sports
Economics, 20(5), 673-694. <a
href="https://doi.org/10.1177/1527002518798686"
class="uri">https://doi.org/10.1177/1527002518798686</a></p>
<p>Heckman, J. J. (1979). Sample Selection Bias as a Specification
Error. Econometrica, 47(1), 153-161. <a
href="https://doi.org/10.2307/1912352"
class="uri">https://doi.org/10.2307/1912352</a></p>
<p>Klein, R. W., &amp; Spady, R. H. (1993). An efficient semiparametric
estimator for binary response models. Econometrica, 61(2), 387-421. <a
href="https://doi.org/10.2307/2951556"
class="uri">https://doi.org/10.2307/2951556</a></p>
<p>Lehman, D. W., &amp; Hahn, J. (2013). Momentum and Organizational
Risk Taking: Evidence from the National Football League. Management
Science, 59(4), 852-868. <a
href="https://doi.org/10.1287/mnsc.1120.1574"
class="uri">https://doi.org/10.1287/mnsc.1120.1574</a></p>
<p>Losak, J. M., Stenquist, R., &amp; Lovett, M. (2023). Behavioral
Biases in Daily Fantasy Baseball: The Case of the Hot Hand. Journal of
Sports Economics, 24(3), 352-372. <a
href="https://doi.org/10.1177/15270025221128955"
class="uri">https://doi.org/10.1177/15270025221128955</a></p>
<p>Owens, M. F., &amp; Roach, M. (2018). Decision-making on the hot seat
and the short list: Evidence from college football fourth down
decisions. Journal of Economic Behavior &amp; Organization, 148,
226-245. <a href="https://doi.org/10.1016/j.jebo.2018.02.023"
class="uri">https://doi.org/10.1016/j.jebo.2018.02.023</a></p>
<p>Roebber, P. J., Schultz, D. M., &amp; Colle, B. A. (2022). On the
existence of momentum in professional football. PLOS ONE, 17(6),
e0269604. <a href="https://doi.org/10.1371/journal.pone.0269604"
class="uri">https://doi.org/10.1371/journal.pone.0269604</a></p>
<p>Romer, D. (2006). Do Firms Maximize? Evidence from Professional
Football. Journal of Political Economy, 114(2), 340-365. <a
href="https://doi.org/10.1086/501171"
class="uri">https://doi.org/10.1086/501171</a></p>
<p>Yam, D., &amp; Lopez, M. (2018). Quantifying the Causal Effects of
Conservative Fourth Down Decision Making in the National Football
League. Available at SSRN: <a href="https://ssrn.com/abstract=3114242"
class="uri">https://ssrn.com/abstract=3114242</a> or <a
href="http://dx.doi.org/10.2139/ssrn.3114242"
class="uri">http://dx.doi.org/10.2139/ssrn.3114242</a></p>
<p>Carl, S., Baldwin, B., Sharpe, L., Ho, T., Edwards, J. (2024).
nflverse. Play-by-play data for NFL games. Retrieved from <a
href="https://nflverse.nflverse.com/">https://nflverse.nflverse.com/</a>.</p>
<p>Pro Football Focus (PFF). (2024). NFL Player Performance Data.
Accessed via subscription at <a
href="https://premium.pff.com/nfl/teams/2024/REGPO">https://premium.pff.com/nfl/teams/2024/REGPO</a>.</p>
<p>Raymond, S. (2024). <em>4th Down Analysis App</em>. Interactive
dashboard for analyzing 4th down decisions in the NFL. Available at: <a
href="https://jzmtko-yigit-aydede.shinyapps.io/NFL_4th_Down_App/">https://jzmtko-yigit-aydede.shinyapps.io/NFL_4th_Down_App/</a>.</p>
<p>Sporting News. (2024). Lions’ Dan Campbell criticized for fourth-down
decisions in playoff loss to 49ers. Retrieved from <a
href="https://www.sportingnews.com/us/nfl/news/lions-49ers-dan-campbell-fourth-down-decisions/b54ce7cc05c4d55fc7b46285">https://www.sportingnews.com/us/nfl/news/lions-49ers-dan-campbell-fourth-down-decisions/b54ce7cc05c4d55fc7b46285</a>.</p>
<p>Davis, M. C., &amp; End, C. M. (2010). A winning proposition: The
economic impact of successful National Football League franchises.
<em>Economic Inquiry</em>, 48(1), 39–50. <a
href="https://doi.org/10.1111/j.1465-7295.2008.00124.x"
class="uri">https://doi.org/10.1111/j.1465-7295.2008.00124.x</a></p>
<p>Birkett, D. (2024, January 21). On this date: Memorable kneecap
speech. Sports Illustrated. Retrieved from <a
href="https://www.si.com/nfl/lions/news/on-this-date-memorable-kneecap-speech"
class="uri">https://www.si.com/nfl/lions/news/on-this-date-memorable-kneecap-speech</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
